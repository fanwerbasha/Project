{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"><B>FARS Analysis</B></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Written By Farjana Anwerbasha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def statename(a):\n",
    "    state={'Alabama':1,'Alaska':2,'Arizona':4,'Arkansas':5,'California':6,'Colorado':8,'Connecticut':9,'Delaware':10,\n",
    "           'District of Columbia':11,'Florida':12,'Georgia':13,'Hawaii':15,'Idaho':16,'Illinois':17,'Indiana':18,'Iowa':19,\n",
    "           'Kansas':20,'Kentucky':21,'Louisiana':22,'Maine':23,'Maryland':24,'Massachusetts':25,'Michigan':26,'Minnesota':27,\n",
    "           'Mississippi':28,'Missouri':29,'Montana':30,'Nebraska':31,'Nevada':32,'New Hampshire':33,'New Jersey':34,\n",
    "           'New Mexico':35,'New York':36,'North Carolina':37,'North Dakota':38,'Ohio':39,'Oklahoma':40,'Oregon':41,\n",
    "           'Pennsylvania':42,'Puerto Rico':43,'Rhode Island':44,'South Carolina':45,'South Dakota':46,'Tennessee':47,\n",
    "           'Texas':48,'Utah':49,'Vermont':50,'Virgin Islands (since 2004)':52,'Virginia':51,'Washington':53,'West Virginia':54,\n",
    "           'Wisconsin':55,'Wyoming':56 }\n",
    "    name=list(state.keys())[list(state.values()).index(a)]\n",
    "    return (name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Created a function named 'statename' and stored the states name in a dictionary 'state'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question No 1\n",
    "##### For each state, what day of the week has the most accidents? Use the DAY_WEEK column. Output the day and the count. For the values output the day name, where 1 is Sunday, 2 is Monday, ... and 7 is Saturday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States    \t\t | Day of week  |    Accidents \n",
      " ------------------------------------------------------\n",
      "Alabama                  |    Saturday  |         166\n",
      "Alaska                   |    Friday    |          15\n",
      "Arizona                  |    Saturday  |         150\n",
      "Arkansas                 |    Monday    |          85\n",
      "California               |    Saturday  |         614\n",
      "Colorado                 |    Friday    |          95\n",
      "Connecticut              |    Thursday  |          50\n",
      "Delaware                 |    Saturday  |          26\n",
      "District of Columbia     |    Friday    |           5\n",
      "Florida                  |    Saturday  |         507\n",
      "Georgia                  |    Saturday  |         258\n",
      "Hawaii                   |    Saturday  |          25\n",
      "Idaho                    |    Friday    |          38\n",
      "Illinois                 |    Saturday  |         202\n",
      "Indiana                  |    Friday    |         127\n",
      "Iowa                     |    Saturday  |          65\n",
      "Kansas                   |    Saturday  |          63\n",
      "Kentucky                 |    Saturday  |         133\n",
      "Louisiana                |    Sunday    |         128\n",
      "Maine                    |    Saturday  |          30\n",
      "Maryland                 |    Saturday  |          96\n",
      "Massachusetts            |    Saturday  |          61\n",
      "Michigan                 |    Saturday  |         175\n",
      "Minnesota                |    Saturday  |          58\n",
      "Mississippi              |    Saturday  |         118\n",
      "Missouri                 |    Saturday  |         156\n",
      "Montana                  |    Saturday  |          34\n",
      "Nebraska                 |    Sunday    |          38\n",
      "Nevada                   |    Saturday  |          56\n",
      "New Hampshire            |    Friday    |          26\n",
      "New Jersey               |    Saturday  |         105\n",
      "New Mexico               |    Saturday  |          69\n",
      "New York                 |    Saturday  |         159\n",
      "North Carolina           |    Saturday  |         219\n",
      "North Dakota             |    Saturday  |          22\n",
      "Ohio                     |    Saturday  |         194\n",
      "Oklahoma                 |    Saturday  |         109\n",
      "Oregon                   |    Saturday  |          76\n",
      "Pennsylvania             |    Friday    |         186\n",
      "Rhode Island             |    Thursday  |          14\n",
      "South Carolina           |    Saturday  |         182\n",
      "South Dakota             |    Saturday  |          18\n",
      "Tennessee                |    Saturday  |         187\n",
      "Texas                    |    Saturday  |         604\n",
      "Utah                     |    Saturday  |          44\n",
      "Vermont                  |    Wednesday |          11\n",
      "Virginia                 |    Saturday  |         139\n",
      "Washington               |    Saturday  |          87\n",
      "West Virginia            |    Wednesday |          41\n",
      "Wisconsin                |    Saturday  |         112\n",
      "Wyoming                  |    Thursday  |          19\n",
      "-----------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "filelist=glob.glob(r'C:\\Users\\fanwerbasha\\Desktop\\FARS\\accident_*.csv')\n",
    "wholelist=[]\n",
    "print('States   ','\\t\\t','|','Day of week ','|','   Accidents',\"\\n\",\"------------------------------------------------------\")\n",
    "for filename in filelist:\n",
    "    df=pd.read_csv(filename,usecols=['DAY_WEEK','STATE'])\n",
    "    wholelist.extend(df.DAY_WEEK)\n",
    "    statenumber=df.STATE[0]\n",
    "    days={'Saturday':7,'Friday':6,'Thursday':5,'Wednesday':4,'Tuesday':3,'Monday':2,'Sunday':1}\n",
    "    eachstatecount=Counter(df.DAY_WEEK).most_common(1)\n",
    "    Maxi_acci_day=list(days.keys())[list(days.values()).index(eachstatecount[0][0])]\n",
    "    print('{:25}''|    ''{:10}''|  ''{:10}'.format(statename(statenumber),Maxi_acci_day,eachstatecount[0][1]))\n",
    "print('-----------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Files under the directory FARS is being read using 'glob' module. \n",
    "##### Reading data file using pandas and saving the specified columns into data-frame\n",
    "##### Creating a dictionary (days) to save days of week\n",
    "##### Simultaneously another list 'wholelist' is being appended with the values of 'day of the week'\n",
    "##### Finding top days of week using counter and most_common module \n",
    "##### Finding days using index of eachstatecount with days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question NO 2\n",
    "##### For whole United States, i.e., all the data, what day of the week has the most accidents? Output the day and the count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In USA most of the accidents occured on'Saturday'and the accident happened at that day is:6104\n",
      "-----------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "wholestatecount=Counter(wholelist).most_common(1)\n",
    "wholestate_Maxi_acci_day=list(days.keys())[list(days.values()).index(wholestatecount[0][0])]\n",
    "print(\"In USA most of the accidents occured on'{:s}'and the accident happened at that day is:{:3}\".format(wholestate_Maxi_acci_day,wholestatecount[0][1]))  \n",
    "print('-----------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using previously created list (wholelist), finding  top accident prone days \n",
    "##### Finding days using index created for days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question No 3\n",
    "##### For each state, what hour of the day has the most accidents? Output the hour and the count.\n",
    "##### A value of 99 in the HOUR means unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States    \t\t |   Prone Hour  |    Accidents \n",
      " ------------------------------------------------------\n",
      "Alabama                  |       16      |          54\n",
      "Alaska                   |        5      |           7\n",
      "Arizona                  |       19      |          65\n",
      "Arkansas                 |       17      |          39\n",
      "California               |       20      |         210\n",
      "Colorado                 |       13      |          38\n",
      "Connecticut              |       17      |          22\n",
      "Delaware                 |       21      |          10\n",
      "District of Columbia     |        2      |           4\n",
      "Florida                  |       21      |         208\n",
      "Georgia                  |       18      |          84\n",
      "Hawaii                   |       20      |          10\n",
      "Idaho                    |       16      |          17\n",
      "Illinois                 |       16      |          64\n",
      "Indiana                  |       17      |          50\n",
      "Iowa                     |       17      |          26\n",
      "Kansas                   |       16      |          28\n",
      "Kentucky                 |       16      |          57\n",
      "Louisiana                |       17      |          48\n",
      "Maine                    |       18      |          12\n",
      "Maryland                 |       22      |          32\n",
      "Massachusetts            |       22      |          25\n",
      "Michigan                 |       18      |          59\n",
      "Minnesota                |       15      |          28\n",
      "Mississippi              |       17      |          41\n",
      "Missouri                 |       18      |          57\n",
      "Montana                  |       21      |          13\n",
      "Nebraska                 |        2      |          14\n",
      "Nevada                   |       23      |          22\n",
      "New Hampshire            |       19      |          11\n",
      "New Jersey               |       18      |          42\n",
      "New Mexico               |       20      |          31\n",
      "New York                 |       17      |          59\n",
      "North Carolina           |       18      |          92\n",
      "North Dakota             |       16      |           9\n",
      "Ohio                     |       19      |          77\n",
      "Oklahoma                 |       16      |          41\n",
      "Oregon                   |       17      |          31\n",
      "Pennsylvania             |       17      |          64\n",
      "Rhode Island             |        1      |           6\n",
      "South Carolina           |       17      |          64\n",
      "South Dakota             |       14      |          10\n",
      "Tennessee                |       16      |          61\n",
      "Texas                    |       20      |         200\n",
      "Utah                     |       13      |          26\n",
      "Vermont                  |       15      |           6\n",
      "Virginia                 |       17      |          60\n",
      "Washington               |       15      |          34\n",
      "West Virginia            |       15      |          24\n",
      "Wisconsin                |       17      |          45\n",
      "Wyoming                  |       12      |          11\n",
      "-----------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('States   ','\\t\\t','|','  Prone Hour ','|','   Accidents',\"\\n\",\"------------------------------------------------------\")\n",
    "wholehourlist=removelist=[]\n",
    "for filename in filelist:\n",
    "    df=pd.read_csv(filename,usecols=['HOUR','STATE'])\n",
    "    filtered = df[(df['HOUR'] != 99)]\n",
    "    wholehourlist.extend(filtered.HOUR)\n",
    "    statenumber=df.STATE[0]\n",
    "    eachsstatehourcount=Counter(filtered.HOUR).most_common(1)\n",
    "    print('{:25}''|    ''{:5}''      |  ''{:10}'.format(statename(statenumber),eachsstatehourcount[0][0],eachsstatehourcount[0][1]))   \n",
    "print('-----------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a data-frame using panda for every state, saving columns 'hour' and 'state'\n",
    "##### Filtering the data-frame with condition ( != 99) and saving it into another data-frame\n",
    "##### creating additional data-frame 'wholehourlist' and extending it with filtered data-frame for next question\n",
    "##### Finding top hours of accidents using counter module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question No : 4\n",
    "##### For whole United States, what hour of the day has the most accidents? Output the hour and the count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In USA most of the accidents occured on hour'18'and the accident happend at that hour is:1984\n",
      "-----------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "wholehourcount=Counter(wholehourlist).most_common(1)\n",
    "print(\"In USA most of the accidents occured on hour'{:}'and the accident happend at that hour is:{:3}\".format(wholehourcount[0][0],wholehourcount[0][1])) \n",
    "print('-----------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using previously created list (wholehourlist), finding top accident prone days\n",
    "##### Finding days using index created for days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question No : 5\n",
    "##### For each state, what is the percentage of fatal accidents involved at least one drunk driver? If the column, DRUNK_DR, has a 0, then no drunk drivers were involved. Any number larger than 0 indicates the number of drunk drivers involved in the accident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States    \t\t | Drunk percentage      | Drunk/total accidents \n",
      " --------------------------------------------------------------------\n",
      "Alabama                  |    14.62 %            |         137 /  937\n",
      "Alaska                   |    44.87 %            |          35 /   78\n",
      "Arizona                  |    23.35 %            |         202 /  865\n",
      "Arkansas                 |    23.36 %            |         114 /  488\n",
      "California               |    23.44 %            |         787 / 3357\n",
      "Colorado                 |    33.69 %            |         188 /  558\n",
      "Connecticut              |    29.54 %            |          83 /  281\n",
      "Delaware                 |    31.03 %            |          36 /  116\n",
      "District of Columbia     |    38.46 %            |          10 /   26\n",
      "Florida                  |    21.24 %            |         623 / 2933\n",
      "Georgia                  |    21.73 %            |         309 / 1422\n",
      "Hawaii                   |    24.77 %            |          27 /  109\n",
      "Idaho                    |    28.45 %            |          66 /  232\n",
      "Illinois                 |    26.42 %            |         265 / 1003\n",
      "Indiana                  |    17.71 %            |         136 /  768\n",
      "Iowa                     |    25.84 %            |          92 /  356\n",
      "Kansas                   |    20.47 %            |          78 /  381\n",
      "Kentucky                 |    24.90 %            |         190 /  763\n",
      "Louisiana                |    29.55 %            |         208 /  704\n",
      "Maine                    |    31.13 %            |          47 /  151\n",
      "Maryland                 |    23.73 %            |         112 /  472\n",
      "Massachusetts            |    28.69 %            |         103 /  359\n",
      "Michigan                 |    24.80 %            |         243 /  980\n",
      "Minnesota                |    27.73 %            |          99 /  357\n",
      "Mississippi              |    16.40 %            |         103 /  628\n",
      "Missouri                 |    27.53 %            |         239 /  868\n",
      "Montana                  |    47.95 %            |          82 /  171\n",
      "Nebraska                 |    38.66 %            |          75 /  194\n",
      "Nevada                   |    29.70 %            |          90 /  303\n",
      "New Hampshire            |    30.00 %            |          39 /  130\n",
      "New Jersey               |    21.97 %            |         125 /  569\n",
      "New Mexico               |    29.05 %            |         104 /  358\n",
      "New York                 |    17.20 %            |         166 /  965\n",
      "North Carolina           |    28.41 %            |         383 / 1348\n",
      "North Dakota             |    48.04 %            |          49 /  102\n",
      "Ohio                     |    33.52 %            |         353 / 1053\n",
      "Oklahoma                 |    27.56 %            |         172 /  624\n",
      "Oregon                   |    26.91 %            |         120 /  446\n",
      "Pennsylvania             |    23.62 %            |         257 / 1088\n",
      "Rhode Island             |    37.50 %            |          18 /   48\n",
      "South Carolina           |    35.47 %            |         332 /  936\n",
      "South Dakota             |    41.75 %            |          43 /  103\n",
      "Tennessee                |    22.57 %            |         218 /  966\n",
      "Texas                    |    24.71 %            |         842 / 3407\n",
      "Utah                     |    19.69 %            |          51 /  259\n",
      "Vermont                  |    47.37 %            |          27 /   57\n",
      "Virginia                 |    29.22 %            |         211 /  722\n",
      "Washington               |    31.55 %            |         159 /  504\n",
      "West Virginia            |    27.60 %            |          69 /  250\n",
      "Wisconsin                |    31.99 %            |         174 /  544\n",
      "Wyoming                  |    29.00 %            |          29 /  100\n",
      "-----------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('States   ','\\t\\t','|',  'Drunk percentage     ' ,'|','Drunk/total accidents',\"\\n\",\"--------------------------------------------------------------------\")\n",
    "wholedrunklist=[];countnonzerolist=[]\n",
    "for filename in filelist:\n",
    "    countzero=countnonzero=0\n",
    "    df=pd.read_csv(filename,usecols=['DRUNK_DR','STATE'])\n",
    "    wholedrunklist.extend(df.DRUNK_DR)\n",
    "    for data in df.DRUNK_DR:\n",
    "        if data>0:\n",
    "            countnonzero+=1\n",
    "    statenumber=df.STATE[0]\n",
    "    datalength=len(df.DRUNK_DR)\n",
    "    percentoffetalaccident=round((countnonzero/datalength)*100,2)\n",
    "    print('{:25}''|    ''{:5.2f}'' %''            |  ''{:10}'' /''{:5}'.format(statename(statenumber),percentoffetalaccident,countnonzero,datalength))\n",
    "    countnonzerolist.append((statenumber,countnonzero)) \n",
    "print('-----------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a data-frame using panda for every state, saving columns 'Drunk_dr' and 'state'\n",
    "##### creating additional data-frame 'wholedrunklist' and extending it with data-frame for next question\n",
    "##### Using for loop, the command checks every drunk_dr field for '0' and '1'and adds value in 'countzero' and 'countnonzero'\n",
    "##### Finding length of the data-frame and store it in 'datalength'\n",
    "##### Deriving 'drunk case percent', by dividing 'countnonzero' with 'length', and multiplying the result with 100. The result is being rounded with 2 decimal points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question No 6\n",
    "##### For whole United States, what is the percentage of fatal accidents involved at least one drunk driver?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Drunk Cases across USA :        8720\n",
      "Total Number of Accidents across USA   :       34439\n",
      "Percentage of Drunk cases across USA   :       25.32 %\n",
      "-----------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "datalengtht=len(wholedrunklist)\n",
    "wholecountzero=wholecountnonzero=0\n",
    "for data in wholedrunklist:\n",
    "    if data!=0:\n",
    "        wholecountnonzero+=1\n",
    "print('Total Number of Drunk Cases across USA : ',str(wholecountnonzero).rjust(10))\n",
    "print(\"Total Number of Accidents across USA   : \",str(datalengtht).rjust(10))    \n",
    "wholepercentoffetalaccident=round((wholecountnonzero/datalengtht)*100,2)\n",
    "print(\"Percentage of Drunk cases across USA   : \",str(wholepercentoffetalaccident).rjust(10), '%')\n",
    "print('-----------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using previously created 'wholedrunklist' in this command\n",
    "##### Using for loop, the command checks every drunk_dr field for '0' and '1' and adds value in 'countzero' and countnonzero'\n",
    "##### Finding length of the data-frame and store it in datalengtht\n",
    "##### Deriving 'drunkcase percent', by diving 'countnonzero'  with 'length', and multiplying the result with 100. The result is being rounded with 2 decimal points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question No 7\n",
    "##### For whole United States, how many fatalities were caused by each type of collision? Use the MAN_COLL column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Types of collision      \t\t| Total accidents \n",
      " --------------------------------------------------------------------\n",
      "Not Collision with Motor Vehicle in Transport   |    21296\n",
      "Front-to-Rear                                   |     2350\n",
      "Front-to-Front                                  |     3511\n",
      "Angle                                           |     6122\n",
      "Sideswipe – Same Direction                      |      519\n",
      "Sideswipe – Opposite Direction                  |      421\n",
      "Rear-to-Side                                    |       32\n",
      "Rear-to-Rear                                    |        2\n",
      "Other (End-Swipes and Others)                   |       86\n",
      "Not Reported                                    |       23\n",
      "Unknown                                         |       77\n",
      "-----------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "wholemancolllist=[]\n",
    "print('            Types of collision     ''','\\t\\t|',  'Total accidents',\"\\n\",\"--------------------------------------------------------------------\")\n",
    "for filename in filelist:\n",
    "    df=pd.read_csv(filename,usecols=['MAN_COLL'])\n",
    "    wholemancolllist.extend(df.MAN_COLL)\n",
    "collision={'Not Collision with Motor Vehicle in Transport':0,'Front-to-Rear':1,'Front-to-Front':2,'Angle':6,\n",
    "           'Sideswipe – Same Direction':7,'Sideswipe – Opposite Direction':8,'Rear-to-Side':9,'Rear-to-Rear':10,\n",
    "           'Other (End-Swipes and Others)':11,'Not Reported':98,'Unknown':99}\n",
    "wholedatamancollcount=Counter(wholemancolllist)\n",
    "value=sorted(wholedatamancollcount.keys(),reverse=False)\n",
    "for data in value:\n",
    "    collisionlist=list(collision.keys())[list(collision.values()).index(data)]\n",
    "    collisionlistcount=list(wholedatamancollcount.values())[list(wholedatamancollcount.keys()).index(data)]\n",
    "    print('{:48}''|    ''{:5}'.format(collisionlist,collisionlistcount))\n",
    "print('-----------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a data-frame using panda for every state, saving columns 'MAN_COLL'\n",
    "##### creating additional data-frame 'wholemancolllist' and extending it with data-frame for next question\n",
    "##### creating a list 'collision' and saving the types of collision described in question\n",
    "##### counting each type of collision using 'counter'module and saving it in 'wholedatamancollcount'\n",
    "##### Sorting the 'wholedatamancollcount' using module 'sorted' with key as index and making it in reverse\n",
    "##### Using for loop, the command prints every collision "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question No : 8\n",
    "##### For each state, what is its fatal accident rate per 10,000 people? To calculate this, count the number of accidents in a state, divide by the state's 2016 population estimate from the nst-est2017-alldata.csv Census data file, and then multiply by 10000. Output the states' rates in order from highest to lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States    \t\t | Accident  rate per 10000 |    Accident / Population \n",
      " ---------------------------------------------------------------------------\n",
      "Mississippi              |          2.10            |         628 /   2985415\n",
      "Alabama                  |          1.93            |         937 /   4860545\n",
      "South Carolina           |          1.89            |         936 /   4959822\n",
      "Kentucky                 |          1.72            |         763 /   4436113\n",
      "New Mexico               |          1.72            |         358 /   2085432\n",
      "Wyoming                  |          1.71            |         100 /    584910\n",
      "Montana                  |          1.65            |         171 /   1038656\n",
      "Arkansas                 |          1.63            |         488 /   2988231\n",
      "Oklahoma                 |          1.59            |         624 /   3921207\n",
      "Louisiana                |          1.50            |         704 /   4686157\n",
      "Tennessee                |          1.45            |         966 /   6649404\n",
      "Missouri                 |          1.43            |         868 /   6091176\n",
      "Florida                  |          1.42            |        2933 /  20656589\n",
      "Georgia                  |          1.38            |        1422 /  10313620\n",
      "Idaho                    |          1.38            |         232 /   1680026\n",
      "West Virginia            |          1.37            |         250 /   1828637\n",
      "North Dakota             |          1.35            |         102 /    755548\n",
      "North Carolina           |          1.33            |        1348 /  10156689\n",
      "Kansas                   |          1.31            |         381 /   2907731\n",
      "Arizona                  |          1.25            |         865 /   6908642\n",
      "Delaware                 |          1.22            |         116 /    952698\n",
      "Texas                    |          1.22            |        3407 /  27904862\n",
      "South Dakota             |          1.20            |         103 /    861542\n",
      "Indiana                  |          1.16            |         768 /   6634007\n",
      "Iowa                     |          1.14            |         356 /   3130869\n",
      "Maine                    |          1.14            |         151 /   1330232\n",
      "Oregon                   |          1.09            |         446 /   4085989\n",
      "Alaska                   |          1.05            |          78 /    741522\n",
      "Nevada                   |          1.03            |         303 /   2939254\n",
      "Nebraska                 |          1.02            |         194 /   1907603\n",
      "Colorado                 |          1.01            |         558 /   5530105\n",
      "Michigan                 |          0.99            |         980 /   9933445\n",
      "New Hampshire            |          0.97            |         130 /   1335015\n",
      "Wisconsin                |          0.94            |         544 /   5772917\n",
      "Ohio                     |          0.91            |        1053 /  11622554\n",
      "Vermont                  |          0.91            |          57 /    623354\n",
      "Virginia                 |          0.86            |         722 /   8414380\n",
      "California               |          0.85            |        3357 /  39296476\n",
      "Pennsylvania             |          0.85            |        1088 /  12787085\n",
      "Utah                     |          0.85            |         259 /   3044321\n",
      "Connecticut              |          0.78            |         281 /   3587685\n",
      "Illinois                 |          0.78            |        1003 /  12835726\n",
      "Maryland                 |          0.78            |         472 /   6024752\n",
      "Hawaii                   |          0.76            |         109 /   1428683\n",
      "Washington               |          0.69            |         504 /   7280934\n",
      "Minnesota                |          0.65            |         357 /   5525050\n",
      "New Jersey               |          0.63            |         569 /   8978416\n",
      "Massachusetts            |          0.53            |         359 /   6823721\n",
      "New York                 |          0.49            |         965 /  19836286\n",
      "Rhode Island             |          0.45            |          48 /   1057566\n",
      "District of Columbia     |          0.38            |          26 /    684336\n",
      "-----------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "totalaccident=result=0;poplist=popfinal=[];populationlist=[]\n",
    "print('States   ','\\t\\t','|','Accident  rate per 10000','|','   Accident / Population',\"\\n\",\"---------------------------------------------------------------------------\")\n",
    "for filename in filelist:\n",
    "    df=pd.read_csv(filename,usecols=['STATE'])\n",
    "    statenumber=df.STATE[0]\n",
    "    totalaccident=int(len(df))\n",
    "    df=pd.read_csv(r'C:\\Users\\fanwerbasha\\Desktop\\FARS\\nst-est2017-alldata.csv',usecols=['STATE','POPESTIMATE2016'])\n",
    "    dropnan=df.dropna(subset=['STATE','POPESTIMATE2016'])\n",
    "    mylist=df.loc[df['STATE']==statenumber,'POPESTIMATE2016'].values.tolist()\n",
    "    population=int(mylist[0])\n",
    "    result=round(totalaccident/population*10000,2)\n",
    "    poplist.append((statename(statenumber),result,totalaccident,population))\n",
    "    populationlist.append((population))  \n",
    "popfinal=sorted(poplist,key=lambda x: x[1], reverse=True)\n",
    "i=0\n",
    "for data in popfinal:\n",
    "    print('{:25}''|    ''{:10.2f}''            |  ''{:>10}'' /''{:10}'.format(popfinal[i][0],popfinal[i][1],popfinal[i][2],popfinal[i][3]))\n",
    "    i+=1\n",
    "print('-----------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a data-frame using panda for every state, saving columns 'STATE'\n",
    "##### Deriving 'totalaccident' by finding length of the data-frame\n",
    "##### creating a data-frame using panda for the poplation data 'nst-est2017-alldata.csv', saving columns 'STATE' and 'POPESTIMATE2016'\n",
    "##### As the panda will append all row/column including empty row/columns with 'nan', we use module 'dropnan' to drop those empty row/column\n",
    "##### Using module 'loc', locating the 'STATE' value with population of corresponding state in data-frame and saving it in 'population'\n",
    "##### Deriving result by dividing 'totalaccident' with 'population' and multiplying it with 10000\n",
    "##### Appending poplist with statename, result, total accident and population\n",
    "##### creating another list populationlist and appending 'population' for next question\n",
    "##### sorting the poplist using module 'sorted' and using 'result' as key to sort in reverse\n",
    "##### using 'for' loop for popfinal and printing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question No : 9\n",
    "##### For each state, what is the rate of fatal accidents caused by drunk driving per 10,000 people? To calculate this, count the number of accidents in which a drunk driver was involved, divide by the state's 2016 population estimate from the nst-est2017-alldata.csv Census data file, and then multiply by 10000. Output the states' rates in order from highest to lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States    \t\t | Drunk rate per 10000     |         Drunk/ Population \n",
      " -------------------------------------------------------------------------------\n",
      "Montana                  |          0.79            |          82 /   1038656\n",
      "South Carolina           |          0.67            |         332 /   4959822\n",
      "North Dakota             |          0.65            |          49 /    755548\n",
      "New Mexico               |          0.50            |         104 /   2085432\n",
      "South Dakota             |          0.50            |          43 /    861542\n",
      "Wyoming                  |          0.50            |          29 /    584910\n",
      "Alaska                   |          0.47            |          35 /    741522\n",
      "Louisiana                |          0.44            |         208 /   4686157\n",
      "Oklahoma                 |          0.44            |         172 /   3921207\n",
      "Kentucky                 |          0.43            |         190 /   4436113\n",
      "Vermont                  |          0.43            |          27 /    623354\n",
      "Idaho                    |          0.39            |          66 /   1680026\n",
      "Missouri                 |          0.39            |         239 /   6091176\n",
      "Nebraska                 |          0.39            |          75 /   1907603\n",
      "Arkansas                 |          0.38            |         114 /   2988231\n",
      "Delaware                 |          0.38            |          36 /    952698\n",
      "North Carolina           |          0.38            |         383 /  10156689\n",
      "West Virginia            |          0.38            |          69 /   1828637\n",
      "Maine                    |          0.35            |          47 /   1330232\n",
      "Mississippi              |          0.35            |         103 /   2985415\n",
      "Colorado                 |          0.34            |         188 /   5530105\n",
      "Tennessee                |          0.33            |         218 /   6649404\n",
      "Nevada                   |          0.31            |          90 /   2939254\n",
      "Florida                  |          0.30            |         623 /  20656589\n",
      "Georgia                  |          0.30            |         309 /  10313620\n",
      "Ohio                     |          0.30            |         353 /  11622554\n",
      "Texas                    |          0.30            |         842 /  27904862\n",
      "Wisconsin                |          0.30            |         174 /   5772917\n",
      "Arizona                  |          0.29            |         202 /   6908642\n",
      "Iowa                     |          0.29            |          92 /   3130869\n",
      "New Hampshire            |          0.29            |          39 /   1335015\n",
      "Oregon                   |          0.29            |         120 /   4085989\n",
      "Alabama                  |          0.28            |         137 /   4860545\n",
      "Kansas                   |          0.27            |          78 /   2907731\n",
      "Virginia                 |          0.25            |         211 /   8414380\n",
      "Michigan                 |          0.24            |         243 /   9933445\n",
      "Connecticut              |          0.23            |          83 /   3587685\n",
      "Washington               |          0.22            |         159 /   7280934\n",
      "Illinois                 |          0.21            |         265 /  12835726\n",
      "Indiana                  |          0.21            |         136 /   6634007\n",
      "California               |          0.20            |         787 /  39296476\n",
      "Pennsylvania             |          0.20            |         257 /  12787085\n",
      "Hawaii                   |          0.19            |          27 /   1428683\n",
      "Maryland                 |          0.19            |         112 /   6024752\n",
      "Minnesota                |          0.18            |          99 /   5525050\n",
      "Rhode Island             |          0.17            |          18 /   1057566\n",
      "Utah                     |          0.17            |          51 /   3044321\n",
      "District of Columbia     |          0.15            |          10 /    684336\n",
      "Massachusetts            |          0.15            |         103 /   6823721\n",
      "New Jersey               |          0.14            |         125 /   8978416\n",
      "New York                 |          0.08            |         166 /  19836286\n",
      "-----------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('States   ','\\t\\t','|',  'Drunk rate per 10000   ' ,' |','        Drunk/ Population',\"\\n\",\"-------------------------------------------------------------------------------\")\n",
    "finallist=list(zip(countnonzerolist,populationlist))\n",
    "i=0;drunklist=drunkfinal=[]\n",
    "for data in finallist:\n",
    "    results=round(finallist[i][0][1]/finallist[i][1]*10000,2)\n",
    "    drunklist.append((statename(finallist[i][0][0]),results,finallist[i][0][1],finallist[i][1]))\n",
    "    i+=1\n",
    "drunkfinal=sorted(drunklist,key=lambda x: x[1], reverse=True)\n",
    "i=0\n",
    "for data in drunkfinal:\n",
    "    print('{:25}''|    ''{:10.2f}''            |  ''{:10}'' /''{:10}'.format(drunkfinal[i][0],drunkfinal[i][1],drunkfinal[i][2],drunkfinal[i][3]))\n",
    "    i+=1\n",
    "print('-----------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using previously created lists 'countnonzerolist' and 'populationlist' and adding both in 'finallist', module'zip' is being used here\n",
    "##### Deriving results by diving 'countnonzero' with 'population' and multiplying the result with 10000. \n",
    "##### Appending statename, results, countnonzero and population to drunklist\n",
    "##### sorting the drunklist using the result as key to sort in reverse and saving it to drunkfinal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
